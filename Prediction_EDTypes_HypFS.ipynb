{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53b3117a-d62a-4e1f-b43e-b3eedb1066b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sreejita/ProjectsPy/GGZ/code_scripts/ED-profiling\n",
      "/home/sreejita/ProjectsPy/GGZ/data/annonymizedDatasets/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import time, itertools, re\n",
    "import importlib\n",
    "from collections import Counter\n",
    "import scipy as sc\n",
    "import miceforest as mf\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score, confusion_matrix, root_mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from sklearn.inspection import permutation_importance\n",
    "from HypOpt import lowest_cwacc\n",
    "import matplotlib.pyplot as plt\n",
    "print(os.getcwd())\n",
    "fileloc_data='/'.join(os.getcwd().split('/')[0:5])+ '/data/annonymizedDatasets/'\n",
    "savetag='pred_lavSQ_MHC'\n",
    "print(fileloc_data)\n",
    "code_path='/'.join(os.getcwd().split('/')[0:4])+'/sklvq/'\n",
    "sys.path.append(code_path)\n",
    "from sklvq import GMLVQ, LGMLVQ\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from EDdataset_GGZ import colsTypeCast    \n",
    "#df_all_combo=pd.read_csv(fileloc_data+'maskedDAIsy7_MainDec_EDEQ_SQ48_MHCSF_Honos_Lav_Visit1.tsv', sep='\\t', decimal=',')\n",
    "#df_adapted_combo, colsExtracted, subscales=colsTypeCast(df_all_combo)\n",
    "#adapted_combo_cols=np.setdiff1d(colsExtracted,\n",
    "#        ['ED_Codes','EDtype', 'SQ48-Score', 'MHCSF-Score', 'Lav-Score']+list(subscales['Honos']))\n",
    "#print(adapted_combo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820ce322-eb03-4179-9302-7556abb7b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from GetDataReady import getDataNormalized_Interact, getDataNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9bfc2f-5bd2-4b04-b239-cb37d82b224f",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5babfd1b-557e-4cf4-abd2-08052c192035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: For dataset with Core, DT, and 5 classes (Ndims=24):\n",
      "\n",
      "Index(['DT-BMI', 'DT-Disorder_Duration_Yrs', 'DT-IND_BDL_CMD',\n",
      "       'DT-IND_OCD_CMD', 'DT-IND_depression_CMD', 'DT-IND_others',\n",
      "       'DT-IND_prev_spec_int_wo_eff', 'DT-num_prev_routes',\n",
      "       'Lav-Dissatisfaction_body', 'Lav-Negative_appraisal_body',\n",
      "       'Lav-Unfamiliarity_with_body', 'MHCSF-Emotional_Well-being',\n",
      "       'MHCSF-Psychological_Well-being', 'MHCSF-Social_Well-being', 'Main-Age',\n",
      "       'SQ48-Agoraphobia', 'SQ48-Anxiety', 'SQ48-Cognitive_Complaints',\n",
      "       'SQ48-Depression', 'SQ48-Hostility', 'SQ48-Social_phobia',\n",
      "       'SQ48-Somatic_Complaints', 'SQ48-Vitality',\n",
      "       'SQ48-Work_related_complaints'],\n",
      "      dtype='object')\n",
      "1.1: For dataset with Core, DT and only ED classes:\n",
      "\n",
      "1.2: For dataset with Core, DT and 3 ED classes and Others:\n",
      "\n",
      "2.0: For dataset with Core, DT, EDEQ subscales and all 5 classes (Ndim=27):\n",
      "\n",
      "Index(['DT-BMI', 'DT-Disorder_Duration_Yrs', 'DT-IND_BDL_CMD',\n",
      "       'DT-IND_OCD_CMD', 'DT-IND_depression_CMD', 'DT-IND_others',\n",
      "       'DT-IND_prev_spec_int_wo_eff', 'DT-num_prev_routes', 'EDEQ-bodyshape',\n",
      "       'EDEQ-eating', 'EDEQ-weight', 'Lav-Dissatisfaction_body',\n",
      "       'Lav-Negative_appraisal_body', 'Lav-Unfamiliarity_with_body',\n",
      "       'MHCSF-Emotional_Well-being', 'MHCSF-Psychological_Well-being',\n",
      "       'MHCSF-Social_Well-being', 'Main-Age', 'SQ48-Agoraphobia',\n",
      "       'SQ48-Anxiety', 'SQ48-Cognitive_Complaints', 'SQ48-Depression',\n",
      "       'SQ48-Hostility', 'SQ48-Social_phobia', 'SQ48-Somatic_Complaints',\n",
      "       'SQ48-Vitality', 'SQ48-Work_related_complaints'],\n",
      "      dtype='object')\n",
      "2.1: For dataset with Core, DT, EDEQ subscales, and only ED classes:\n",
      "\n",
      "2.2: For dataset with Core, DT, EDEQ subscales and 3 ED classes and Others:\n",
      "\n",
      "3.0: For dataset with Core only, and all 5 classes (Ndim=16):\n",
      "\n",
      "Index(['Lav-Dissatisfaction_body', 'Lav-Negative_appraisal_body',\n",
      "       'Lav-Unfamiliarity_with_body', 'MHCSF-Emotional_Well-being',\n",
      "       'MHCSF-Psychological_Well-being', 'MHCSF-Social_Well-being', 'Main-Age',\n",
      "       'SQ48-Agoraphobia', 'SQ48-Anxiety', 'SQ48-Cognitive_Complaints',\n",
      "       'SQ48-Depression', 'SQ48-Hostility', 'SQ48-Social_phobia',\n",
      "       'SQ48-Somatic_Complaints', 'SQ48-Vitality',\n",
      "       'SQ48-Work_related_complaints'],\n",
      "      dtype='object')\n",
      "3.1: For dataset with Core only, and only ED classes:\n",
      "\n",
      "3.2: For dataset with Core, and 3 ED classes and Others:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "choice_dict={1.0: 'Core-DT, 5Cls', 1.1: 'Core-DT, only ED', 1.2: 'Core-DT, 3 ED and Others',\n",
    "    2.0: 'Core-DT-EDEQ subscale, 5Cls', 2.1: 'Core-DT-EDEQ subscale, only ED', 2.2: 'Core-DT-EDEQ subscale, 3 ED and Others',\n",
    "    3.0: 'Core, 5Cls', 3.1: 'Core, only ED', 3.2: 'Core, 3 ED and Others'}\n",
    "savepicklpath='%s/pickles/'%(os.getcwd())\n",
    "dataset_type='allCombiAllExps'#'Core_DT'#save_dict[choice]\n",
    "model_fname='cls-%s.pkl'%dataset_type\n",
    "modelsClassify1='%s%s'%(savepicklpath, model_fname)\n",
    "save_dict={1.0: 'Core-DT-5Cls', 1.1: 'Core-DT-onlyED', 1.2: 'Core-DT-3ED-Others',\n",
    "    2.0: 'Core-DT-EDEQ-5Cls', 2.1: 'Core-DT-EDEQ-only-ED', 2.2: 'Core-DT-EDEQ-3ED-Others',\n",
    "    3.0: 'Core-5Cls', 3.1: 'Core-onlyED', 3.2: 'Core-3ED-Others'}\n",
    "dataset_types={}\n",
    "%autoreload 2\n",
    "from HypOpt import GridSearchClassifiers, GridSearch_LVQ\n",
    "sampling_strategy='not majority'\n",
    "param_grid={'RF_Max_Features': [5,7,10, 20,25], 'RF_n_Trees':[100, 300, 500], 'RF_min_leaf':5,\n",
    "           'scorer_name':'Lowest_CWA', 'LRL1_C': np.array([0.001, 0.01, 0.1, 1])}\n",
    "for key, val in choice_dict.items():\n",
    "    dataset_types[key]=getDataNormalized(key)\n",
    "    X,Y=dataset_types[key]['zXtrain'], dataset_types[key]['Ytrain']  \n",
    "    if key>=3:        \n",
    "        if X.isnull().sum().sum()>0:\n",
    "            X,Y=dataset_types[key]['mice_zXtrain'], dataset_types[key]['Ytrain'] \n",
    "    if key in [1.0,2.0,3.0]:\n",
    "        print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30bee1b-f46d-4d66-ad2e-baa53f6b77c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: For dataset with Core, DT, and 5 classes (Ndims=24):\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "2      500             5    0.515159\n",
      "4      300             7    0.512460\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.376111\n",
      "2  0.1    0.253254\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "0  3   minkowski    0.452381\n",
      "3  3      cosine    0.440317\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "0    svd    0.389444\n",
      "1   lsqr    0.389444\n",
      "Linear SVM: \n",
      "        C  Lowest_CWA\n",
      "5  100.0    0.504365\n",
      "4   10.0    0.493730\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "32  100.0   0.01    0.624048\n",
      "26   10.0   0.01    0.532143\n",
      "1.1: For dataset with Core, DT and only ED classes:\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "2      500             5    0.553968\n",
      "0      100             5    0.543095\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.499524\n",
      "2  0.1    0.316270\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.517302\n",
      "0  3   minkowski    0.476032\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "2  eigen    0.525238\n",
      "0    svd    0.507063\n",
      "Linear SVM: \n",
      "        C  Lowest_CWA\n",
      "5  100.0    0.574286\n",
      "4   10.0    0.563968\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "32  100.0   0.01    0.698254\n",
      "26   10.0   0.01    0.577302\n",
      "1.2: For dataset with Core, DT and 3 ED classes and Others:\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "3      100             7    0.715794\n",
      "7      300            10    0.715635\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.596984\n",
      "2  0.1    0.475635\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.588651\n",
      "0  3   minkowski    0.545476\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "0    svd     0.58381\n",
      "1   lsqr     0.58381\n",
      "Linear SVM: \n",
      "       C  Lowest_CWA\n",
      "3   1.0    0.685714\n",
      "4  10.0    0.682857\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "32  100.0   0.01    0.770397\n",
      "26   10.0   0.01    0.736270\n",
      "2.0: For dataset with Core, DT, EDEQ subscales and all 5 classes (Ndim=27):\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "7      300            10    0.593016\n",
      "8      500            10    0.588175\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.486587\n",
      "2  0.1    0.314048\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.480079\n",
      "0  3   minkowski    0.437222\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "0    svd    0.411587\n",
      "1   lsqr    0.411587\n",
      "Linear SVM: \n",
      "       C  Lowest_CWA\n",
      "4  10.0    0.570873\n",
      "3   1.0    0.567937\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "32  100.0   0.01    0.671111\n",
      "26   10.0   0.01    0.590952\n",
      "2.1: For dataset with Core, DT, EDEQ subscales, and only ED classes:\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "5      500             7    0.651270\n",
      "3      100             7    0.647063\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.551746\n",
      "2  0.1    0.403333\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.596508\n",
      "0  3   minkowski    0.533968\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "0    svd    0.520556\n",
      "1   lsqr    0.520556\n",
      "Linear SVM: \n",
      "        C  Lowest_CWA\n",
      "5  100.0    0.614921\n",
      "3    1.0    0.590079\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "32  100.0   0.01    0.684444\n",
      "26   10.0   0.01    0.622460\n",
      "2.2: For dataset with Core, DT, EDEQ subscales and 3 ED classes and Others:\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "2      500             5    0.700714\n",
      "5      500             7    0.696508\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.573175\n",
      "2  0.1    0.452778\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.575635\n",
      "0  3   minkowski    0.548968\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "2  eigen    0.562063\n",
      "0    svd    0.535159\n",
      "Linear SVM: \n",
      "       C  Lowest_CWA\n",
      "3   1.0    0.708016\n",
      "4  10.0    0.662460\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "32  100.0   0.01    0.717381\n",
      "26   10.0   0.01    0.696905\n",
      "3.0: For dataset with Core only, and all 5 classes (Ndim=16):\n",
      "\n",
      "RF: \n",
      "     n_Trees  Max_Features  Lowest_CWA\n",
      "5       500             7    0.452000\n",
      "13      300            25    0.446667\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.293333\n",
      "2  0.1    0.158667\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.378667\n",
      "0  3   minkowski    0.361333\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "0    svd       0.272\n",
      "1   lsqr       0.272\n",
      "Linear SVM: \n",
      "        C  Lowest_CWA\n",
      "5  100.0    0.329333\n",
      "4   10.0    0.322667\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "27   10.0    1.0    0.473333\n",
      "33  100.0    1.0    0.473333\n",
      "3.1: For dataset with Core only, and only ED classes:\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "1      300             5    0.524000\n",
      "2      500             5    0.522667\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.408000\n",
      "2  0.1    0.261333\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.549333\n",
      "0  3   minkowski    0.490667\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "0    svd       0.436\n",
      "1   lsqr       0.436\n",
      "Linear SVM: \n",
      "       C  Lowest_CWA\n",
      "4  10.0    0.476000\n",
      "3   1.0    0.473333\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "32  100.0   0.01    0.589333\n",
      "27   10.0   1.00    0.582667\n",
      "3.2: For dataset with Core, and 3 ED classes and Others:\n",
      "\n",
      "RF: \n",
      "    n_Trees  Max_Features  Lowest_CWA\n",
      "4      300             7    0.554667\n",
      "7      300            10    0.552000\n",
      "LogLASSO: \n",
      "      C  Lowest_CWA\n",
      "3  1.0    0.444000\n",
      "2  0.1    0.337333\n",
      "KNN: \n",
      "    K Dist Metric  Lowest_CWA\n",
      "3  3      cosine    0.484000\n",
      "0  3   minkowski    0.429333\n",
      "LDA: \n",
      "   Solver  Lowest_CWA\n",
      "0    svd    0.466667\n",
      "1   lsqr    0.466667\n",
      "Linear SVM: \n",
      "        C  Lowest_CWA\n",
      "5  100.0    0.464000\n",
      "4   10.0    0.461333\n",
      "RBF SVM: \n",
      "         C  Gamma  Lowest_CWA\n",
      "27   10.0    1.0        0.56\n",
      "33  100.0    1.0        0.56\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from HypOpt import GridSearchClassifiers, GridSearch_LVQ\n",
    "sampling_strategy='not majority'\n",
    "param_grid={'RF_Max_Features': [5,7,10, 20,25], 'RF_n_Trees':[100, 300, 500], 'RF_min_leaf':5,\n",
    "           'scorer_name':'Lowest_CWA', 'LRL1_C': np.array([0.001, 0.01, 0.1, 1])}\n",
    "dataset_types={}\n",
    "for key, val in choice_dict.items():\n",
    "    dataset_types[key]=getDataNormalized(key)\n",
    "    X,Y=dataset_types[key]['zXtrain'], dataset_types[key]['Ytrain']  \n",
    "    if key<3:        \n",
    "        if X.isnull().sum().sum()>0:\n",
    "            X,Y=dataset_types[key]['mice_zXtrain'], dataset_types[key]['Ytrain']  \n",
    "    GridSearchClassifiers(X, Y,sampling_strategy, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "44c28fbf-82dc-4d53-bb5b-1692c8b3bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice is  1.2\n",
      "     Prot per cls Solver  Num Component Activation type  Reg term  Lowest_CWA\n",
      "307  [3, 2, 1, 1]   adam             15           swish     0.001    0.699242 \n",
      "     Prot per cls Solver  Num Component Activation type  Lowest_CWA\n",
      "34  [3, 3, 2, 1]  lbfgs              7        identity    0.729293\n",
      "Matching LGMLVQ is:\n",
      "     Prot per cls Solver  Num Component Activation type  Lowest_CWA\n",
      "200  [3, 2, 1, 1]    sgd             20           swish    0.721717\n",
      "198  [3, 2, 1, 1]  lbfgs             15           swish    0.719949\n",
      "202  [3, 2, 1, 1]  lbfgs             20           swish    0.718939\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "fname_pkl1, fname_pkl2='Hyp_LVQ.pkl', 'Hyp_LVQ2.pkl'\n",
    "savepicklpath='%s/pickles/'%(os.getcwd())\n",
    "LVQModels1, LVQModels2='%s%s'%(savepicklpath, fname_pkl1), '%s%s'%(savepicklpath, fname_pkl2)\n",
    "choice, rows=1.2,[]\n",
    "if os.path.exists(LVQModels1):\n",
    "        LVQClassifiers1 = pickle.load(open(LVQModels1, \"rb\"))#LVQClassifiers2 = pickle.load(open(LVQModels2, \"rb\"))print('LVQ1: ',LVQClassifiers1.keys())#print('LVQ2: ',LVQClassifiers2.keys())\n",
    "print('Choice is ',choice)\n",
    "print(LVQClassifiers1[choice]['GMLVQ'].head(1),'\\n', LVQClassifiers1[choice]['LGMLVQ'][cols_disp].head(1))\n",
    "g_prot_per_cls=LVQClassifiers1[choice]['GMLVQ']['Prot per cls'].to_numpy()[0]\n",
    "l_prot_per_cls=LVQClassifiers1[choice]['LGMLVQ']['Prot per cls'].to_numpy()\n",
    "print('Matching LGMLVQ is:')\n",
    "for idx in range(0,10):\n",
    "    if np.sum(l_prot_per_cls[idx]==g_prot_per_cls)==len(g_prot_per_cls):\n",
    "        rows.append(idx)\n",
    "cols_disp=['Prot per cls','Solver', 'Num Component','Activation type', 'Lowest_CWA']\n",
    "print(LVQClassifiers1[choice]['LGMLVQ'][cols_disp].iloc[rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe04276-3560-4c28-94b0-ce74da97b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters, nreps=5,10#pipeClassifiers=[]\n",
    "use_permutation_imp=['KNN','LDA','QDA','LSVC','RSVC']\n",
    "nTrees, max_ftrs=np.array([500,500,100, 300,500,500, 500,300,300]), np.array([5,5,7, 10,7,5, 7,5,7])\n",
    "C_LR,knn=np.array([1,1,1, 1,1,1, 1,1,1]), np.array([3,3,3, 3,3,3, 3,3,3])\n",
    "knn_metric=['minkowski','cosine','cosine', 'cosine','cosine','cosine', 'cosine','cosine','cosine']\n",
    "lda_solver=['svd','eigen','svd', 'svd','svd','eigen',  'svd', 'svd','svd']\n",
    "C_Lin, C_RBF=np.array([100,100,1, 10,100,1, 100,10,100]),np.array([100,100,100, 100,100,100, 10, 100, 10])\n",
    "svd_gamma=np.array([0.01,0.01, 0.01, 0.01, 0.01, 0.01, 1, 0.01, 1])\n",
    "s_glob={1.0:'adam',1.1:'lbfgs',1.2:'adam', 2.0:'lbfgs',2.1:'lbfgs',2.2:'lbfgs',3.0:'lbfgs',3.1:'lbfgs',3.2:'lbfgs'}\n",
    "s_loc1={1.0:'lbfgs',1.1:'lbfgs',1.2:'lbfgs',2.0:'lbfgs',2.1:'lbfgs',2.2: 'lbfgs', 3.0:'lbfgs',3.1:'adam',3.2:'lbfgs'}\n",
    "s_loc2={1.0:'lbfgs',1.1:'lbfgs',1.2:'sgd',2.0:'lbfgs',2.1:'lbfgs',2.2: 'lbfgs', 3.0:'lbfgs',3.1:'adam',3.2:'lbfgs'}\n",
    "act_g={1.0:'swish', 1.1:'swish',1.2:'swish',2.0:'swish',2.1:'identity', 2.2:'swish',\n",
    "       3.0:'swish',3.1:'swish',3.2:'swish'}\n",
    "act_l1={1.0:'swish',1.1:'swish', 1.2:'identity', 2.0:'identity',2.1:'swish',2.2:'identity',\n",
    "        3.0:'identity',3.1:'swish',3.2: 'identity' }\n",
    "act_l2={1.0:'swish',1.1:'identity', 1.2:'swish', 2.0:'identity',2.1:'swish',2.2:'swish',\n",
    "        3.0:'swish',3.1:'swish',3.2: 'identity' }\n",
    "rel_comp_gmlvq={1.0:'20', 1.1:'7', 1.2:'15', 2.0:'5', 2.1:'20', 2.2:'15', 3.0:'10', 3.1:'7', 3.2:'15'}\n",
    "rel_comp_lgmlvq1={1.0:'10', 1.1:'15', 1.2:'7', 2.0:'20', 2.1:'7', 2.2:'20', 3.0:'5', 3.1:'15', 3.2:'7'}\n",
    "rel_comp_lgmlvq2={1.0:'10', 1.1:'20', 1.2:'20', 2.0:'10', 2.1:'7', 2.2:'20', 3.0:'5', 3.1:'15', 3.2:'7'}\n",
    "g_num_prots_all={1.0:np.array([2, 2, 2, 1, 1]),1.1:np.array([3, 2, 1, 1]),1.2:np.array([3, 2, 1, 1]),\n",
    "        2.0:np.array([3, 2, 2, 1, 1]), 2.1:np.array([3,2, 2, 1]), 2.2:np.array([3, 2, 1, 1]),\n",
    "        3.0:np.array([3, 2, 2, 1, 1]), 3.1:np.array([3, 2, 1, 1]),3.2:np.array([3,3,2,1])}\n",
    "l_num_prots_all1={1.0:np.array([2, 2, 2, 1, 1]),1.1:np.array([3, 3, 2, 1]),1.2:np.array([3, 3, 2, 1]),\n",
    "        2.0:np.array([3, 3, 3, 1, 1]),2.1:np.array([2, 1, 2, 1]), 2.2:np.array([3, 2, 2, 1]),\n",
    "        3.0:np.array([3,3,3, 1, 1]), 3.1:np.array([3,3, 2, 1]), 3.2:np.array([3,3, 2, 1])}\n",
    "l_num_prots_all2=g_num_prots_all.copy()\n",
    "reg_comp, rel_loc=np.array([0.001,0, 0.001, 0.001,0,0.01, 0,0.01, 0.0]),'class'\n",
    "pipeClassifiers_all, c={},0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7466ff1-902d-487f-aee2-0d92726629be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final Core-DT-5Cls Classification models complete\n",
      "Saving final Core-DT-5Cls models complete\n",
      "Training final Core-DT-onlyED Classification models complete\n",
      "Saving final Core-DT-onlyED models complete\n",
      "Training final Core-DT-3ED-Others Classification models complete\n",
      "Saving final Core-DT-3ED-Others models complete\n",
      "Training final Core-DT-EDEQ-5Cls Classification models complete\n",
      "Saving final Core-DT-EDEQ-5Cls models complete\n",
      "Training final Core-DT-EDEQ-only-ED Classification models complete\n",
      "Saving final Core-DT-EDEQ-only-ED models complete\n",
      "Training final Core-DT-EDEQ-3ED-Others Classification models complete\n",
      "Saving final Core-DT-EDEQ-3ED-Others models complete\n",
      "Training final Core-5Cls Classification models complete\n",
      "Saving final Core-5Cls models complete\n",
      "Training final Core-onlyED Classification models complete\n",
      "Saving final Core-onlyED models complete\n",
      "Training final Core-3ED-Others Classification models complete\n",
      "Saving final Core-3ED-Others models complete\n"
     ]
    }
   ],
   "source": [
    "for keyD, val in choice_dict.items():\n",
    "    dataset_type=save_dict[keyD]#'Core_DT'#save_dict[choice]\n",
    "    model_fname='%s_clf2.pkl'%dataset_type\n",
    "    modelsClassify='%s%s'%(savepicklpath, model_fname)\n",
    "    modelsClassify_permut='%s%s_%s.pkl'%(savepicklpath,dataset_type, 'FtrImp')    \n",
    "    Y=dataset_types[keyD]['Ytrain']  \n",
    "    if keyD>=3:        \n",
    "        X=dataset_types[keyD]['zXtrain']  \n",
    "    else:\n",
    "        X=dataset_types[keyD]['mice_zXtrain']\n",
    "    if ~(os.path.exists(modelsClassify)) | ~(os.path.exists(modelsClassify_permut)):\n",
    "        clf_all, temp, permut_model, all_prots={},{}, {},{}\n",
    "        for iter in range(iters):            \n",
    "            pipeRF=Pipeline(steps=[('RF', RandomForestClassifier(criterion=\"gini\", min_samples_leaf=5,\n",
    "                                    n_estimators=nTrees[c], max_features=max_ftrs[c], random_state=iter))])\n",
    "            pipeKNN=Pipeline(steps=[('KNN', KNeighborsClassifier(n_neighbors=knn[c],metric=knn_metric[c]))])\n",
    "            pipeLDA=Pipeline(steps=[('LDA',LinearDiscriminantAnalysis(solver=lda_solver[c], ))])\n",
    "            pipeQDA=Pipeline(steps=[('QDA', QuadraticDiscriminantAnalysis(reg_param=0.01))])\n",
    "            pipeLSVC=Pipeline(steps=[('LSVC', SVC(kernel=\"linear\", C=C_Lin[c], probability=True, \n",
    "                                                  random_state=iter))])\n",
    "            pipeRSVC=Pipeline(steps=[('RSVC', SVC(kernel='rbf', C=C_RBF[c], gamma=svd_gamma[c], \n",
    "                                                  probability=True, random_state=iter))])\n",
    "            pipeGMLVQ=Pipeline(steps=[('GMLVQ',GMLVQ(distance_type='adaptive-squared-euclidean',\n",
    "                solver_type=s_glob[keyD],random_state=iter,prototype_n_per_class=g_num_prots_all[keyD], \n",
    "                relevance_regularization=reg_comp[c],activation_type=act_g[keyD],\n",
    "                relevance_n_components=int(rel_comp_gmlvq[keyD])))])\n",
    "            pipeLGMLVQ1=Pipeline(steps=[('LGMLVQ1', LGMLVQ(distance_type='local-adaptive-squared-euclidean', \n",
    "                  random_state=iter,prototype_n_per_class=l_num_prots_all1[keyD], activation_type=act_l1[keyD],\n",
    "                  relevance_localization=rel_loc,solver_type=s_loc1[keyD],\n",
    "                  relevance_n_components=int(rel_comp_lgmlvq1[keyD])))])   \n",
    "            pipeLGMLVQ2=Pipeline(steps=[('LGMLVQ2', LGMLVQ(distance_type='local-adaptive-squared-euclidean', \n",
    "                random_state=iter,prototype_n_per_class=l_num_prots_all2[keyD], activation_type=act_l2[keyD], \n",
    "                solver_type=s_loc2[keyD],relevance_n_components=int(rel_comp_lgmlvq2[keyD]),\n",
    "                relevance_localization=rel_loc))])   \n",
    "            pipeGNB=Pipeline(steps=[('GNB', GaussianNB())])\n",
    "            pipeLogLASSO=Pipeline(steps=[('LogLASSO',LogisticRegression(C=C_LR[c], solver='saga',\n",
    "                            class_weight='balanced',penalty='l1', random_state=iter))])\n",
    "            pipeClassifiers_all={'RF':pipeRF, 'KNN':pipeKNN, 'LDA':pipeLDA, 'QDA': pipeQDA, 'LSVC': pipeLSVC, \n",
    "                      'RSVC': pipeRSVC, 'GMLVQ': pipeGMLVQ, 'LGMLVQ1': pipeLGMLVQ1, 'LGMLVQ2': pipeLGMLVQ2, \n",
    "                      'GNB': pipeGNB,'LogLASSO':pipeLogLASSO}\n",
    "            for keyClf, clf in pipeClassifiers_all.items():\n",
    "                clf.fit(X, Y)\n",
    "                clf_all[str(iter)+'-'+keyClf]=clf\n",
    "                if keyClf in use_permutation_imp:\n",
    "                    permimp = permutation_importance(clf, X, Y, n_repeats=nreps, scoring=make_scorer(lowest_cwacc))\n",
    "                    permut_model[str(iter)+'-'+keyClf]=permimp.importances\n",
    "                if keyClf in ['GMLVQ', 'LGMLVQ1', 'LGMLVQ2']:    \n",
    "                    all_prots[str(iter)+'-'+keyClf]=clf[keyClf].prototypes_ \n",
    "        print('Training final %s Classification models complete'%dataset_type)\n",
    "        pipe_per_clf, permut_per_clf, prots_per_clf={},{},{}\n",
    "        for temp_clf in pipeClassifiers_all.keys():\n",
    "            temp_per_clf, temp_permut_per_clf, temp_prots =[],[],[]\n",
    "            for tempK, tempV in clf_all.items():    \n",
    "                itr, keyClf_temp=tempK.split('-')\n",
    "                if keyClf_temp==temp_clf:\n",
    "                    temp_per_clf.append(tempV)\n",
    "                    if temp_clf in use_permutation_imp: \n",
    "                        temp_permut_clf=permut_model[tempK]\n",
    "                        temp_permut_per_clf.append(temp_permut_clf)\n",
    "                    if temp_clf in ['GMLVQ', 'LGMLVQ1', 'LGMLVQ2']:  \n",
    "                        temp_prots.append(all_prots[tempK])\n",
    "            pipe_per_clf[temp_clf]=temp_per_clf.copy()\n",
    "            if temp_clf in use_permutation_imp:\n",
    "                permut_per_clf[temp_clf]=temp_permut_per_clf.copy()\n",
    "            if temp_clf in ['GMLVQ', 'LGMLVQ1', 'LGMLVQ2']:\n",
    "                prots_per_clf[temp_clf]=temp_prots.copy()                  \n",
    "        del pipeClassifiers_all, temp_per_clf, temp_prots, temp_permut_per_clf\n",
    "        with open(modelsClassify, 'wb') as f:  # open a text file\n",
    "            pickle.dump(pipe_per_clf, f) \n",
    "        with open('%s'%modelsClassify_permut, 'wb') as f:  # open a text file\n",
    "            pickle.dump(permut_per_clf, f) \n",
    "        modelsClassify_prots='%s%s_%s.pkl'%(savepicklpath,dataset_type, 'Prots')  \n",
    "        with open('%s'%modelsClassify_prots, 'wb') as f:  # open a text file\n",
    "            pickle.dump(prots_per_clf, f) \n",
    "        print('Saving final %s models complete'%dataset_type)\n",
    "        del clf_all, permut_model\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cacbf5-7024-4818-bff1-aee724f39ce9",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a7d3219-db26-4fc4-b064-5df2c593f47c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "KNN: \n",
      "    K Dist Metric     Score  Abs_Score\n",
      "3  3      cosine -0.250908   0.250908\n",
      "1  5   minkowski -0.252987   0.252987\n",
      "2  7   minkowski -0.253428   0.253428\n",
      "5  7      cosine -0.257942   0.257942\n",
      "RF: \n",
      "     n_Trees  Max_Features       Criterion     Score  Abs_Score\n",
      "27      100            25  absolute_error -0.236910   0.236910\n",
      "59      500            25         poisson -0.237573   0.237573\n",
      "58      300            25         poisson -0.237780   0.237780\n",
      "56      500            20         poisson -0.238342   0.238342\n",
      "Linear SVM: \n",
      "        C     Score  Abs_Score\n",
      "2    0.1 -0.227737   0.227737\n",
      "3    1.0 -0.231015   0.231015\n",
      "4   10.0 -0.231967   0.231967\n",
      "5  100.0 -0.231985   0.231985\n",
      "RBF SVM: \n",
      "         C   Gamma     Score  Abs_Score\n",
      "31  100.0  0.0010 -0.225034   0.225034\n",
      "26   10.0  0.0100 -0.225551   0.225551\n",
      "25   10.0  0.0010 -0.242093   0.242093\n",
      "30  100.0  0.0001 -0.242156   0.242156\n",
      "3.0\n",
      "KNN: \n",
      "    K Dist Metric     Score  Abs_Score\n",
      "1  5   minkowski -0.228309   0.228309\n",
      "2  7   minkowski -0.231111   0.231111\n",
      "0  3   minkowski -0.236836   0.236836\n",
      "4  5      cosine -0.237039   0.237039\n",
      "RF: \n",
      "     n_Trees  Max_Features      Criterion     Score  Abs_Score\n",
      "44      500            10        poisson -0.226133   0.226133\n",
      "30      100            10   friedman_mse -0.226889   0.226889\n",
      "40      300             7        poisson -0.227084   0.227084\n",
      "3       100             7  squared_error -0.227270   0.227270\n",
      "Linear SVM: \n",
      "        C     Score  Abs_Score\n",
      "5  100.0 -0.227634   0.227634\n",
      "3    1.0 -0.227678   0.227678\n",
      "4   10.0 -0.227782   0.227782\n",
      "2    0.1 -0.228291   0.228291\n",
      "RBF SVM: \n",
      "         C   Gamma     Score  Abs_Score\n",
      "26   10.0  0.0100 -0.217149   0.217149\n",
      "31  100.0  0.0010 -0.218077   0.218077\n",
      "30  100.0  0.0001 -0.232769   0.232769\n",
      "25   10.0  0.0010 -0.233224   0.233224\n"
     ]
    }
   ],
   "source": [
    "# %autoreload 2\n",
    "#import importlib\n",
    "#importlib.reload(\n",
    "from HypOptRegress import GridSearchRegressors\n",
    "choice_regs=[1.0, 3.0]\n",
    "for keyD, val in choice_dict.items():\n",
    "    if keyD in choice_regs:    \n",
    "        if keyD>=3:        \n",
    "            X=dataset_types[keyD]['zXtrain']  \n",
    "            param_grid={'RF_Max_Features': [5,7,10,16], 'RF_n_Trees':[100, 300, 500], 'RF_min_leaf':5,\n",
    "           'scorer_name':'Lowest_CWA', 'LRL1_C': np.array([0.001, 0.01, 0.1, 1])}\n",
    "        else:\n",
    "            X=dataset_types[keyD]['mice_zXtrain']\n",
    "            param_grid={'RF_Max_Features': [5,7,10, 20,25], 'RF_n_Trees':[100, 300, 500], 'RF_min_leaf':5,\n",
    "           'scorer_name':'Lowest_CWA', 'LRL1_C': np.array([0.001, 0.01, 0.1, 1])}\n",
    "        Y=dataset_types[keyD]['Ytrain_reg']   \n",
    "        print(keyD)\n",
    "        param_grid_reg={'scorer': 'neg_root_mean_squared_log_error', 'RF':param_grid}\n",
    "        GridSearchRegressors(X, Y, param_grid_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9544e7ce-d67a-4d62-9bea-2ac9034819e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e8cf372-529c-4ef9-8e6a-27d2db8e782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['RF', 'KNN', 'LSVC', 'RSVC', 'LASSOReg'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51d30969-3ddc-4ab2-841f-e84997731c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled files found\n",
      "Exp-1RF Training: R2= 0.800 (0.001), RMSE= 0.560 (0.001)\n",
      "Exp-1RF Test: R2= 0.659 (0.004), RMSE= 0.826 (0.004)\n",
      "Exp-1KNN Training: R2= 0.751 (0.000), RMSE= 0.625 (0.000)\n",
      "Exp-1KNN Test: R2= 0.452 (0.000), RMSE= 1.047 (0.000)\n",
      "Exp-1LSVC Training: R2= 0.614 (0.000), RMSE= 0.778 (0.000)\n",
      "Exp-1LSVC Test: R2= 0.495 (0.000), RMSE= 1.005 (0.000)\n",
      "Exp-1RSVC Training: R2= 0.686 (0.000), RMSE= 0.702 (0.000)\n",
      "Exp-1RSVC Test: R2= 0.522 (0.000), RMSE= 0.978 (0.000)\n",
      "Exp-1LASSOReg Training: R2= 0.593 (0.000), RMSE= 0.800 (0.000)\n",
      "Exp-1LASSOReg Test: R2= 0.634 (0.000), RMSE= 0.856 (0.000)\n",
      "Pickled files found\n",
      "Exp-3RF Training: R2= 0.804 (0.001), RMSE= 0.536 (0.002)\n",
      "Exp-3RF Test: R2= 0.628 (0.001), RMSE= 0.820 (0.001)\n",
      "Exp-3KNN Training: R2= 0.726 (0.000), RMSE= 0.634 (0.000)\n",
      "Exp-3KNN Test: R2= 0.369 (0.000), RMSE= 1.068 (0.000)\n",
      "Exp-3LSVC Training: R2= 0.584 (0.000), RMSE= 0.781 (0.000)\n",
      "Exp-3LSVC Test: R2= 0.606 (0.000), RMSE= 0.844 (0.000)\n",
      "Exp-3RSVC Training: R2= 0.634 (0.000), RMSE= 0.733 (0.000)\n",
      "Exp-3RSVC Test: R2= 0.608 (0.000), RMSE= 0.842 (0.000)\n",
      "Exp-3LASSOReg Training: R2= 0.597 (0.000), RMSE= 0.769 (0.000)\n",
      "Exp-3LASSOReg Test: R2= 0.645 (0.000), RMSE= 0.802 (0.000)\n"
     ]
    }
   ],
   "source": [
    "knn_met, knn_k=['cosine', 'minkowski'], [3,5]\n",
    "rf_tree,rf_ftr, rf_crit=[500,100],[20,7],['poisson', 'squared_error']\n",
    "lsvm, c=[0.1,0.01], 0\n",
    "rsvm_c, rsvm_g=[100, 10],[0.001,0.01]\n",
    "iters=5\n",
    "for keyD, val in choice_dict.items():\n",
    "    if keyD in choice_regs:    \n",
    "        dataset_type=save_dict[keyD]#'Core_DT'#save_dict[choice]\n",
    "        model_fname='%s_reg2.pkl'%dataset_type\n",
    "        modelsRegress='%s%s'%(savepicklpath, model_fname)          \n",
    "        Ytrain, Ytest=dataset_types[keyD]['Ytrain_reg'], dataset_types[keyD]['Ytest_reg']               \n",
    "        if keyD>=3: \n",
    "            Xtrain, Xtest=dataset_types[keyD]['zXtrain'], dataset_types[keyD]['zXtest']\n",
    "        else:\n",
    "            Xtrain, Xtest=dataset_types[keyD]['mice_zXtrain'], dataset_types[keyD]['mice_zXtest']\n",
    "        if os.path.exists(modelsRegress):\n",
    "            print('Pickled files found')#pickle.load(open('%s'%modelsClassify_permut, \"rb\"))\n",
    "            regressor_all=pickle.load(open('%s'%modelsRegress, \"rb\"))\n",
    "            for keyReg in regressor_all.keys():            \n",
    "                perf_dict=regressor_all[keyReg]['Performance']\n",
    "                for split in ['Training', 'Test']:\n",
    "                    print('Exp-%d%s %s: R2= %.3f (%.3f), RMSE= %.3f (%.3f)'%(keyD, keyReg, split,\n",
    "                                    perf_dict[keyReg+split]['R2(mean)'], perf_dict[keyReg+split]['R2(std)'],\n",
    "                                    perf_dict[keyReg+split]['RMSE(mean)'], perf_dict[keyReg+split]['RMSE(std)']))\n",
    "        else:\n",
    "            print('Pickled files not present yet')\n",
    "            reg_all, regressor_all, perf_dict={},{},{}\n",
    "            tr_perf, te_perf=np.zeros((2, iters)), np.zeros((2, iters))\n",
    "            train_perf_all, test_perf_all={},{}            \n",
    "            pipeRF=Pipeline(steps=[('RF', RandomForestRegressor(criterion=rf_crit[c], min_samples_leaf=5,\n",
    "                                        n_estimators=rf_tree[c], max_features=rf_ftr[c]))])\n",
    "            pipeKNN=Pipeline(steps=[('KNN', KNeighborsRegressor(n_neighbors=knn_k[c],metric=knn_met[c]))])                        \n",
    "            pipeLSVR=Pipeline(steps=[('LinSVC', SVR(kernel=\"linear\", C=lsvm[c]))])\n",
    "            pipeRSVR=Pipeline(steps=[('RbfSVC', SVR(kernel='rbf', C=rsvm_c[c], gamma=rsvm_g[c]))])\n",
    "            pipeLASSO=Pipeline(steps=[('LASSO', LassoCV(cv=5))])\n",
    "            pipeRegressors={'RF':pipeRF, 'KNN':pipeKNN, 'LSVC': pipeLSVR, 'RSVC': pipeRSVR,\n",
    "                            'LASSOReg': pipeLASSO}            \n",
    "            for keyReg, reg in pipeRegressors.items():\n",
    "                for iter in range(iters):\n",
    "                    reg.fit(Xtrain, Ytrain)\n",
    "                    reg_all[str(iter)+'-'+keyReg]=reg\n",
    "                    train_pred_labs_eds=reg.predict(Xtrain)\n",
    "                    test_pred_labs_eds=reg.predict(Xtest)\n",
    "                    tr_perf[0,iter]=r2_score(Ytrain, train_pred_labs_eds)\n",
    "                    te_perf[0,iter]=r2_score(Ytest, test_pred_labs_eds)\n",
    "                    tr_perf[1,iter]=root_mean_squared_error(Ytrain, train_pred_labs_eds)\n",
    "                    te_perf[1,iter]=root_mean_squared_error(Ytest, test_pred_labs_eds)                \n",
    "                train_perf_all[keyReg], test_perf_all[keyReg]=tr_perf, te_perf\n",
    "                perf_dict[keyReg+'Training']={'R2(mean)': np.mean(tr_perf[0,:]),'R2(std)': np.std(tr_perf[0,:]),\n",
    "                                'RMSE(mean)': np.mean(tr_perf[1,:]),'RMSE(std)': np.std(tr_perf[1,:])}\n",
    "                perf_dict[keyReg+'Test']={'R2(mean)': np.mean(te_perf[0,:]),'R2(std)': np.std(te_perf[0,:]),\n",
    "                                      'RMSE(mean)': np.mean(te_perf[1,:]),'RMSE(std)': np.std(te_perf[1,:])}\n",
    "                regressor_all[keyReg]={'Models': reg_all, 'Performance': perf_dict}\n",
    "                for split in ['Training', 'Test']:\n",
    "                    print('Exp-%d%s %s: R2= %.3f (%.3f), RMSE= %.3f (%.3f)'%(keyD, keyReg, split,\n",
    "                                perf_dict[keyReg+split]['R2(mean)'], perf_dict[keyReg+split]['R2(std)'],\n",
    "                                perf_dict[keyReg+split]['RMSE(mean)'], perf_dict[keyReg+split]['RMSE(std)']))\n",
    "            with open(modelsRegress, 'wb') as f:  # open a text file\n",
    "                pickle.dump(regressor_all, f)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361afa8e-28d5-4b27-b47d-0510ec7ecabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

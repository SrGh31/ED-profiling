{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb61d648-e96d-40e1-8f7f-afb4e25d292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sreejita/ProjectsPy/GGZ/code_scripts/ED-profiling\n",
      "/home/sreejita/ProjectsPy/GGZ/data/annonymizedDatasets/\n",
      "/home/sreejita/ProjectsPy/GGZ/code_scripts/ED-profiling\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path, sys\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV, LassoCV, LogisticRegression\n",
    "import importlib\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.spatial import ConvexHull\n",
    "import seaborn as sns\n",
    "print(os.getcwd())\n",
    "fileloc_data='/'.join(os.getcwd().split('/')[0:5])+ '/data/annonymizedDatasets/'\n",
    "name_mapping=pd.read_csv('/'.join(os.getcwd().split('/')[0:5])+ '/data/Map_1.csv', sep=',')\n",
    "savetag='pred_lavSQ_MHC'\n",
    "print(fileloc_data)\n",
    "code_path='/'.join(os.getcwd().split('/')[0:4])+'/sklvq/'\n",
    "sys.path.append(code_path)\n",
    "from sklvq import GMLVQ, LGMLVQ\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis,)\n",
    "from sklearn.svm import SVC\n",
    "from EDdataset_GGZ import colsTypeCast\n",
    "%load_ext autoreload\n",
    "from GetDataReady import getDataNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6ff5c9-ff2c-40b8-a2cc-4de0353bd1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: For dataset with Core, DT, and 5 classes (Ndims=24):\n",
      "\n",
      "1.1: For dataset with Core, DT and only ED classes:\n",
      "\n",
      "1.2: For dataset with Core, DT and 3 ED classes and Others:\n",
      "\n",
      "2.0: For dataset with Core, DT, EDEQ subscales and all 5 classes (Ndim=27):\n",
      "\n",
      "2.1: For dataset with Core, DT, EDEQ subscales, and only ED classes:\n",
      "\n",
      "2.2: For dataset with Core, DT, EDEQ subscales and 3 ED classes and Others:\n",
      "\n",
      "3.0: For dataset with Core only, and all 5 classes (Ndim=16):\n",
      "\n",
      "3.1: For dataset with Core only, and only ED classes:\n",
      "\n",
      "3.2: For dataset with Core, and 3 ED classes and Others:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "choice_dict={1.0: 'Core-DT, 5Cls', 1.1: 'Core-DT, only ED', 1.2: 'Core-DT, 3 ED and Others',\n",
    "    2.0: 'Core-DT-EDEQ subscale, 5Cls', 2.1: 'Core-DT-EDEQ subscale, only ED', 2.2: 'Core-DT-EDEQ subscale, 3 ED and Others',\n",
    "    3.0: 'Core, 5Cls', 3.1: 'Core, only ED', 3.2: 'Core, 3 ED and Others'}\n",
    "save_dict={1.0: 'Core-DT-5Cls', 1.1: 'Core-DT-onlyED', 1.2: 'Core-DT-3ED-Others',\n",
    "    2.0: 'Core-DT-EDEQ-5Cls', 2.1: 'Core-DT-EDEQ-only-ED', 2.2: 'Core-DT-EDEQ-3ED-Others',\n",
    "    3.0: 'Core-5Cls', 3.1: 'Core-onlyED', 3.2: 'Core-3ED-Others'}\n",
    "use_permutation_imp=['KNN','LDA','QDA','LSVC','RSVC']\n",
    "savepicklpath='%s/pickles/'%(os.getcwd())\n",
    "dataset_types={}\n",
    "for key, val in choice_dict.items():\n",
    "    dataset_types[key]=getDataNormalized(key)\n",
    "ftr_imp_pkls='%s/rearr_ftr_weights.pkl'%savepicklpath\n",
    "if os.path.exists('%s/rearr_ftr_weights.pkl'%savepicklpath):\n",
    "    with open('%s/rearr_ftr_weights.pkl'%savepicklpath, 'rb') as f: \n",
    "        fimp_all_exps=pickle.load(f)\n",
    "if os.path.exists('%s/rearr_prots_lvq.pkl'%savepicklpath):\n",
    "    with open('%s/rearr_prots_lvq.pkl'%savepicklpath, 'rb') as f:  # open a text file\n",
    "        prots_lvq_all=pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ec2442-8442-448c-9fef-0a520f243f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core-DT-onlyED\n",
      "['Anorexia nervosa' 'Binge-ED' 'Bulimia nervosa' 'Other ED']\n"
     ]
    }
   ],
   "source": [
    "choice=1.1\n",
    "model_fname='%s_clf2.pkl'%dataset_type\n",
    "modelsClassify='%s%s'%(savepicklpath, model_fname)\n",
    "pipeClassifiers_all = pickle.load(open(modelsClassify, \"rb\"))\n",
    "select_keys1, classifier_name1=['RF', 'KNN','RSVC', 'LDA','GMLVQ'],['Random Forest', 'K-nearest neighbour', 'SVM w/ RBF',\n",
    "                                                                    'Linear Discr. Analysis','Generalized Matrix LVQ']\n",
    "select_keys2, exp_name=['GNB','LGMLVQ2', 'LogLASSO'], save_dict[choice]\n",
    "X, Y=dataset_types[choice]['zXtrain'], dataset_types[choice]['Ytrain']\n",
    "Xtest=dataset_types[choice]['zXtest']\n",
    "X.rename(columns=dict(zip(name_mapping['Current'].to_list(), name_mapping['Updated'].to_list())), inplace=True)\n",
    "Xtest.rename(columns=dict(zip(name_mapping['Current'].to_list(), name_mapping['Updated'].to_list())), inplace=True)\n",
    "nclasses, fimp_all=len(np.unique(Y)), fimp_all_exps[choice]\n",
    "adapted_combo_cols=X.columns\n",
    "ind = np.arange(len(adapted_combo_cols)-1)\n",
    "mean_name, std_name, show_col_names=[],[], []\n",
    "for idx, col in enumerate(adapted_combo_cols):\n",
    "    if (col.split('-')[0]=='Main') | (col=='DT-BMI'):\n",
    "        col=col.split('-')[1]   \n",
    "    show_col_names.append(' '.join(col.split('_')))\n",
    "    col='('+col+')'\n",
    "    all_parts=' '.join(col.split('_'))    #temp='mean '+ all_parts\n",
    "    mean_name.append('mean '+ all_parts)# temp='std '+ all_parts\n",
    "    std_name.append('std '+ all_parts)\n",
    "mpl.rcParams['hatch.linewidth'] = 0.5\n",
    "res_df_colname=np.column_stack((mean_name, std_name)).flatten()\n",
    "patterns = [ \"/\" , \"++\", \"..\", \"xx\", \"\\\\\" , \"+\" , \"o\", \"O\", \"*\", \"|\"  ]\n",
    "colors=[np.array([228,26,28])/256, np.array([200,0,210])/256, np.array([77,175,74])/256, np.array([56,108,176])/256, \n",
    "        np.array([255,127,0]) /256, np.array([191,91,23])/256, np.array([231,41,138])/256, np.array([247,129,191])/256]\n",
    "fs, alpha, ind2=10,0.6, ind\n",
    "print(exp_name)\n",
    "print(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb763154-67aa-48d6-ba11-a04e1948bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig01, ax01=plt.subplots(2,4, figsize=(12,6), layout='constrained')\n",
    "for keyClf, clf in pipeClassifiers_all.items():          \n",
    "    if ~keyClf in ['LGMLVQ1', 'LGMLVQ2']:\n",
    "        train_pred_labs, test_pred_labs=clf[iter].predict(zXTrain), clf[iter].predict(zXTest)\n",
    "        transformedTrain, transformedTest=clf.transform(zXTrain), clf.transform(zXTest)\n",
    "        cls_idx=np.median(transformedTrain[YTrain== k], axis=0), np.where(class_members)[0]\n",
    "        if keyClf=='GMLVQ':\n",
    "            prot=clf.prototypes_            \n",
    "        else:\n",
    "            prot=np.median(transformedTrain[YTrain], axis=1)\n",
    "        pwdists=[np.linalg.norm(prot-row) for row in data_to_plot[cls_idx,:]]\n",
    "        sort_idx=np.argsort(np.abs(pwdists))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
